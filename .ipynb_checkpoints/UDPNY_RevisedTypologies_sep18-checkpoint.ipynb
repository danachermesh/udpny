{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDPNY 2018 - _phase #3_\n",
    "# _new edition according to udp methodology and revision - September '18_\n",
    "\n",
    "This code defines the _**8 displacement typologies**_ and assignes each tract to a typology. \n",
    "\n",
    "- [UDP's methodology / displacement typollogies](https://drive.google.com/file/d/1nwOoVItI5RLLILrFpbTRoXbrjIohnSPY/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# UDP Gentrification and Displacement Typologies\n",
    "The typologies (**Updated to October 2018**) can be found in the udp website under _[Gentrification and Displacement Census Tract Typologies](https://drive.google.com/file/d/1nwOoVItI5RLLILrFpbTRoXbrjIohnSPY/view])_\n",
    "### _8 Typologies_ to be generated to the displacement map:\n",
    "\n",
    "### Low Income:\n",
    "1. LI - Not Losing Low-Income Households\n",
    "2. LI - At Risk of Gentrification\n",
    "3. LI - Ongoing Displacement of Low-Income Households\n",
    "4. LI - Ongoing Gentrification \n",
    "\n",
    "### Moderate to High Income:\n",
    "5. MHI - Advanced Gentrification\n",
    "6. MHI - Not Losing Low-Income Households\n",
    "7. MHI - At Risk of Exclusion\n",
    "8. MHI - Displacement of Low-Income Households - Ongoing Exclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data \n",
    "- This notebook uses the data was given by the Berkeley UDP team for the New-York region;\n",
    "- For the data aquisition process, including logistic regressions for the variables please refer to https://github.com/geeroovaa/udp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4525, 144)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>empd02</th>\n",
       "      <th>TOD</th>\n",
       "      <th>TOD_pre_00</th>\n",
       "      <th>TOD_00_10</th>\n",
       "      <th>TOD_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>364</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   empd02    TOD  TOD_pre_00  TOD_00_10  TOD_10\n",
       "0     398  False       False      False   False\n",
       "1     222  False       False      False   False\n",
       "2     364  False       False      False   False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unhash this if reading .dta file\n",
    "\n",
    "# data = pd.read_stata(\"data/UDP_NYC_Variables.dta\")\n",
    "data = pd.read_csv(\"udp/UDPNY_gerardo.csv\")\n",
    "data = data.drop(['county_x', 'county_y', 'state_x', 'state_y','tract_x', 'tract_y'], axis=1)\n",
    "data = data.iloc[:,:-61]\n",
    "\n",
    "print(data.shape)\n",
    "data.iloc[:3,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'NAME',\n",
       " 'county',\n",
       " 'hh_00',\n",
       " 'hh_16',\n",
       " 'hh_16_moe',\n",
       " 'hh_90',\n",
       " 'hi_00',\n",
       " 'hi_16',\n",
       " 'hi_16_moe',\n",
       " 'hi_90',\n",
       " 'hi_mig_10',\n",
       " 'hi_mig_10_moe',\n",
       " 'hi_mig_16',\n",
       " 'hi_mig_16_moe',\n",
       " 'hinc_00',\n",
       " 'hinc_16',\n",
       " 'hinc_16_moe',\n",
       " 'hinc_90',\n",
       " 'hu_00',\n",
       " 'hu_16',\n",
       " 'hu_16_moe',\n",
       " 'hu_90',\n",
       " 'li_00',\n",
       " 'li_16',\n",
       " 'li_16_moe',\n",
       " 'li_90',\n",
       " 'li_mig_10',\n",
       " 'li_mig_10_moe',\n",
       " 'li_mig_16',\n",
       " 'li_mig_16_moe',\n",
       " 'mhi_00',\n",
       " 'mhi_16',\n",
       " 'mhi_16_moe',\n",
       " 'mhi_90',\n",
       " 'mhi_mig_10',\n",
       " 'mhi_mig_10_moe',\n",
       " 'mhi_mig_16',\n",
       " 'mhi_mig_16_moe',\n",
       " 'mhval_00',\n",
       " 'mhval_16',\n",
       " 'mhval_16_moe',\n",
       " 'mhval_90',\n",
       " 'mi_00',\n",
       " 'mi_16',\n",
       " 'mi_16_moe',\n",
       " 'mi_90',\n",
       " 'mi_mig_10',\n",
       " 'mi_mig_10_moe',\n",
       " 'mi_mig_16',\n",
       " 'mi_mig_16_moe',\n",
       " 'mrent_00',\n",
       " 'mrent_16',\n",
       " 'mrent_16_moe',\n",
       " 'mrent_90',\n",
       " 'per_all_li_mig_10',\n",
       " 'per_all_li_mig_16',\n",
       " 'per_asian_00',\n",
       " 'per_asian_16',\n",
       " 'per_asian_16_moe',\n",
       " 'per_asian_90',\n",
       " 'per_black_00',\n",
       " 'per_black_16',\n",
       " 'per_black_16_moe',\n",
       " 'per_black_90',\n",
       " 'per_built_00_16',\n",
       " 'per_built_80_90',\n",
       " 'per_built_90_00',\n",
       " 'per_burden_00',\n",
       " 'per_burden_16',\n",
       " 'per_car_commute_90',\n",
       " 'per_col_00',\n",
       " 'per_col_16',\n",
       " 'per_col_16_moe',\n",
       " 'per_col_90',\n",
       " 'per_commute_high_00',\n",
       " 'per_commute_high_16',\n",
       " 'per_commute_high_16_moe',\n",
       " 'per_commute_high_90',\n",
       " 'per_commute_low_00',\n",
       " 'per_commute_low_16',\n",
       " 'per_commute_low_16_moe',\n",
       " 'per_commute_low_90',\n",
       " 'per_commute_med_00',\n",
       " 'per_commute_med_16',\n",
       " 'per_commute_med_16_moe',\n",
       " 'per_commute_med_90',\n",
       " 'per_foreign_00',\n",
       " 'per_foreign_16',\n",
       " 'per_foreign_16_moe',\n",
       " 'per_foreign_90',\n",
       " 'per_hhwchild_00',\n",
       " 'per_hhwchild_16',\n",
       " 'per_hhwchild_16_moe',\n",
       " 'per_hhwchild_90',\n",
       " 'per_latino_00',\n",
       " 'per_latino_16',\n",
       " 'per_latino_16_moe',\n",
       " 'per_latino_90',\n",
       " 'per_nonwhite_00',\n",
       " 'per_nonwhite_16',\n",
       " 'per_nonwhite_16_moe',\n",
       " 'per_nonwhite_90',\n",
       " 'per_owners_00',\n",
       " 'per_owners_16',\n",
       " 'per_owners_16_moe',\n",
       " 'per_owners_90',\n",
       " 'per_rent_00',\n",
       " 'per_rent_16',\n",
       " 'per_rent_16_moe',\n",
       " 'per_rent_90',\n",
       " 'per_units_post80',\n",
       " 'per_units_pre50',\n",
       " 'per_units_pre50_16',\n",
       " 'pop_00',\n",
       " 'pop_16',\n",
       " 'pop_16_moe',\n",
       " 'pop_90',\n",
       " 'renters_pre_1979_16',\n",
       " 'state',\n",
       " 'tract',\n",
       " 'vhi_00',\n",
       " 'vhi_16',\n",
       " 'vhi_16_moe',\n",
       " 'vhi_90',\n",
       " 'vhi_mig_10',\n",
       " 'vhi_mig_10_moe',\n",
       " 'vhi_mig_16',\n",
       " 'vhi_mig_16_moe',\n",
       " 'vli_00',\n",
       " 'vli_16',\n",
       " 'vli_16_moe',\n",
       " 'vli_90',\n",
       " 'vli_mig_10',\n",
       " 'vli_mig_10_moe',\n",
       " 'vli_mig_16',\n",
       " 'vli_mig_16_moe',\n",
       " 'downtown',\n",
       " 'empd15',\n",
       " 'empd02',\n",
       " 'TOD',\n",
       " 'TOD_pre_00',\n",
       " 'TOD_00_10',\n",
       " 'TOD_10']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data cleaning and munging\n",
    "- Dropping tracts with _**population less than 500**_ (2016)\n",
    "- Dropping tracts with _**more than 5 'Null' columns**_\n",
    "- calculating coefficient of variation according to MOE (drop **_> 30% of variation_**)\n",
    "- reading in tracts' shapefile in order to claculate _**pop densities**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tracts in data before cleaning:  4525\n",
      "# of tracts in data after cleaning:  4525\n"
     ]
    }
   ],
   "source": [
    "print(\"# of tracts in data before cleaning: \", data.shape[0])\n",
    "\n",
    "# Dropping tracts with population less than 500 (2016)\n",
    "data = data[data['pop_16'] > 500]\n",
    "# Dropping tracts with more than 5 'Null' columns\n",
    "data = data[data.isnull().sum(axis=1) <= 5]\n",
    "\n",
    "print(\"# of tracts in data after cleaning: \", data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of variation of MOE\n",
    "## _Tracts with a coefficient of variation > 30% on several key 2016 variables are flagged and determined unreliable:_\n",
    "- Population -- V\n",
    "- Housing units -- V\n",
    "- Median rent -- V\n",
    "- Median home value -- V\n",
    "- Median income  -- **_no MOE in the data_**\n",
    "- College count\n",
    "- Renter count -- V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4505, 144)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Population\n",
    "data = data[(data.pop_16_moe / 1.645 ) / data.pop_16 <= 0.3]\n",
    "# Housing Units\n",
    "data = data[(data.hu_16_moe / 1.645 ) / data.hu_16 <= 0.3]\n",
    "# Bachelors count\n",
    "data = data[(data.per_col_16_moe / 1.645 ) / data.per_col_16 <= 0.3]\n",
    "\n",
    "# Renter counts, Median rent, Median home value\n",
    "# dividing data to ct with majority of renters vs homeowners\n",
    "datarent = data[data.per_rent_16 > 0.5]\n",
    "dataowner = data[data.per_rent_16 <= 0.5]\n",
    "\n",
    "# Renter count, ownership counts\n",
    "# datarent = datarent[(datarent.moe_renter16 / 1.645)  / datarent.rhu16 <= 0.3]\n",
    "# dataowner = dataowner[(dataowner.moe_owner16 / 1.645 ) / dataowner.ohu16 <= 0.3]\n",
    "\n",
    "# Median rent, Median home value\n",
    "datarent = datarent[(datarent.mrent_16_moe / 1.645)  / datarent.mrent_16 <= 0.3]\n",
    "dataowner = dataowner[(dataowner.mhval_16_moe / 1.645 ) / dataowner.mhval_16 <= 0.3]\n",
    "\n",
    "# concatenating two datasets back to 'data'\n",
    "data = [dataowner, datarent]\n",
    "data = pd.concat(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004419889502762431"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4525-data.shape[0]) / 4525"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Dana update final no._ >>\n",
    "#### _4,758 CT were found valid for the analysis -- 8.3% were dropped._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census tracts shapefiles + calculating population densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0\n",
      "7   34001001300\n",
      "14  34001010101\n",
      "15  34001010102\n",
      "16  34001010200\n",
      "17  34001010300\n",
      "Unnamed: 0    object\n",
      "NAME          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[:5,:1])\n",
    "\n",
    "data['Unnamed: 0'] = data['Unnamed: 0'].astype(str)\n",
    "print(data.iloc[:,:2].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5297, 3)\n",
      "GEOID        object\n",
      "ALAND_mi    float64\n",
      "geometry     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>ALAND_mi</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34003003200</td>\n",
       "      <td>0.47916</td>\n",
       "      <td>POLYGON ((-74.000221 40.914034, -73.9994909999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34003003402</td>\n",
       "      <td>0.40644</td>\n",
       "      <td>POLYGON ((-74.01045499999999 40.914168, -74.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34003004002</td>\n",
       "      <td>0.42869</td>\n",
       "      <td>POLYGON ((-74.03627399999999 40.879097, -74.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34003015500</td>\n",
       "      <td>1.43050</td>\n",
       "      <td>POLYGON ((-73.984858 40.87487, -73.98401799999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34003023401</td>\n",
       "      <td>0.16760</td>\n",
       "      <td>POLYGON ((-74.06457 40.887063, -74.062236 40.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GEOID  ALAND_mi                                           geometry\n",
       "0  34003003200   0.47916  POLYGON ((-74.000221 40.914034, -73.9994909999...\n",
       "1  34003003402   0.40644  POLYGON ((-74.01045499999999 40.914168, -74.00...\n",
       "2  34003004002   0.42869  POLYGON ((-74.03627399999999 40.879097, -74.03...\n",
       "3  34003015500   1.43050  POLYGON ((-73.984858 40.87487, -73.98401799999...\n",
       "4  34003023401   0.16760  POLYGON ((-74.06457 40.887063, -74.062236 40.8..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alltracts = gpd.GeoDataFrame.from_file(\"data/MM_Tracts_CSA-NYMetro/MM_Tracts_CSA-NYMetro.shp\")\n",
    "Alltracts = Alltracts[Alltracts['CSA'] == '408'].reset_index()\n",
    "Alltracts = Alltracts[['GEOID', 'ALAND_mi', 'geometry']]\n",
    "\n",
    "print(Alltracts.shape)\n",
    "print(Alltracts.dtypes)\n",
    "Alltracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "(3369, 145)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>NAME</th>\n",
       "      <th>county</th>\n",
       "      <th>hh_00</th>\n",
       "      <th>hh_16</th>\n",
       "      <th>hh_16_moe</th>\n",
       "      <th>hh_90</th>\n",
       "      <th>hi_00</th>\n",
       "      <th>hi_16</th>\n",
       "      <th>hi_16_moe</th>\n",
       "      <th>...</th>\n",
       "      <th>vli_mig_16</th>\n",
       "      <th>vli_mig_16_moe</th>\n",
       "      <th>downtown</th>\n",
       "      <th>empd15</th>\n",
       "      <th>empd02</th>\n",
       "      <th>TOD</th>\n",
       "      <th>TOD_pre_00</th>\n",
       "      <th>TOD_00_10</th>\n",
       "      <th>TOD_10</th>\n",
       "      <th>pop_density16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34003023401</th>\n",
       "      <td>POLYGON ((-74.06457 40.887063, -74.062236 40.8...</td>\n",
       "      <td>Census Tract 234.01, Bergen County, New Jersey</td>\n",
       "      <td>3</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>1714.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>0.073389</td>\n",
       "      <td>0.085915</td>\n",
       "      <td>0.052043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502505</td>\n",
       "      <td>0.225005</td>\n",
       "      <td>False</td>\n",
       "      <td>461</td>\n",
       "      <td>478</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23013.126492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34003030100</th>\n",
       "      <td>POLYGON ((-74.08288399999999 40.879418, -74.08...</td>\n",
       "      <td>Census Tract 301, Bergen County, New Jersey</td>\n",
       "      <td>3</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.067959</td>\n",
       "      <td>0.037526</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719520</td>\n",
       "      <td>0.315516</td>\n",
       "      <td>False</td>\n",
       "      <td>2316</td>\n",
       "      <td>2634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6412.055759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34003033300</th>\n",
       "      <td>POLYGON ((-74.068018 40.889893, -74.0670339999...</td>\n",
       "      <td>Census Tract 333, Bergen County, New Jersey</td>\n",
       "      <td>3</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>0.110583</td>\n",
       "      <td>0.053873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613109</td>\n",
       "      <td>0.224883</td>\n",
       "      <td>False</td>\n",
       "      <td>732</td>\n",
       "      <td>786</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10517.251798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34003041200</th>\n",
       "      <td>POLYGON ((-73.99802099999999 40.84664799999999...</td>\n",
       "      <td>Census Tract 412, Bergen County, New Jersey</td>\n",
       "      <td>3</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.100269</td>\n",
       "      <td>0.078678</td>\n",
       "      <td>0.049537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618532</td>\n",
       "      <td>0.284393</td>\n",
       "      <td>False</td>\n",
       "      <td>359</td>\n",
       "      <td>646</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24231.982529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34003046300</th>\n",
       "      <td>POLYGON ((-74.03238399999999 40.858634, -74.02...</td>\n",
       "      <td>Census Tract 463, Bergen County, New Jersey</td>\n",
       "      <td>3</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>1626.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.057626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561222</td>\n",
       "      <td>0.247962</td>\n",
       "      <td>False</td>\n",
       "      <td>1324</td>\n",
       "      <td>1341</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12260.893395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      geometry  \\\n",
       "GEOID                                                            \n",
       "34003023401  POLYGON ((-74.06457 40.887063, -74.062236 40.8...   \n",
       "34003030100  POLYGON ((-74.08288399999999 40.879418, -74.08...   \n",
       "34003033300  POLYGON ((-74.068018 40.889893, -74.0670339999...   \n",
       "34003041200  POLYGON ((-73.99802099999999 40.84664799999999...   \n",
       "34003046300  POLYGON ((-74.03238399999999 40.858634, -74.02...   \n",
       "\n",
       "                                                       NAME  county   hh_00  \\\n",
       "GEOID                                                                         \n",
       "34003023401  Census Tract 234.01, Bergen County, New Jersey       3  1785.0   \n",
       "34003030100     Census Tract 301, Bergen County, New Jersey       3  2053.0   \n",
       "34003033300     Census Tract 333, Bergen County, New Jersey       3  1366.0   \n",
       "34003041200     Census Tract 412, Bergen County, New Jersey       3  1336.0   \n",
       "34003046300     Census Tract 463, Bergen County, New Jersey       3  1847.0   \n",
       "\n",
       "              hh_16  hh_16_moe   hh_90     hi_00     hi_16  hi_16_moe  \\\n",
       "GEOID                                                                   \n",
       "34003023401  1714.0      105.0  1764.0  0.073389  0.085915   0.052043   \n",
       "34003030100  1952.0      139.0  2018.0  0.067959  0.037526   0.030701   \n",
       "34003033300  1407.0       65.0  1374.0  0.112518  0.110583   0.053873   \n",
       "34003041200  1667.0       87.0  1220.0  0.100269  0.078678   0.049537   \n",
       "34003046300  1626.0      101.0  1859.0  0.087125  0.115068   0.057626   \n",
       "\n",
       "                 ...        vli_mig_16  vli_mig_16_moe  downtown  empd15  \\\n",
       "GEOID            ...                                                       \n",
       "34003023401      ...          0.502505        0.225005     False     461   \n",
       "34003030100      ...          0.719520        0.315516     False    2316   \n",
       "34003033300      ...          0.613109        0.224883     False     732   \n",
       "34003041200      ...          0.618532        0.284393     False     359   \n",
       "34003046300      ...          0.561222        0.247962     False    1324   \n",
       "\n",
       "             empd02    TOD  TOD_pre_00  TOD_00_10  TOD_10  pop_density16  \n",
       "GEOID                                                                     \n",
       "34003023401     478  False       False      False   False   23013.126492  \n",
       "34003030100    2634  False       False      False   False    6412.055759  \n",
       "34003033300     786  False       False      False   False   10517.251798  \n",
       "34003041200     646  False       False      False   False   24231.982529  \n",
       "34003046300    1341  False       False      False   False   12260.893395  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shp = Alltracts.merge(data, left_on='GEOID', right_on='Unnamed: 0').drop('Unnamed: 0', axis=1)\\\n",
    "                                                                              .set_index('GEOID')\n",
    "\n",
    "# calculate pop density at 2016\n",
    "data_shp['pop_density16'] = data_shp['pop_16'] / data_shp['ALAND_mi']\n",
    "\n",
    "# replicating data_shp to data\n",
    "data = data_shp.drop(['ALAND_mi'], axis=1)\n",
    "\n",
    "print(type(data_shp))\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1d707f98>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['pop_density16'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Creating conditional (binary) variables prior classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLI - Very Low Income tract at 2016 -- _for additional layer on top of typologies_\n",
    "- vhi2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vli2016'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3064\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3065\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vli2016'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-11009265d9b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculating median for vli and vli % of all hh in tract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmedian_vli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vli2016'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m print(\"the median of very low income households at the year 2016 from total households, \"  \n\u001b[1;32m      5\u001b[0m       \"of all census tracts is: {:.2f}\".format(median_vli))\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \"\"\"\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0mgeo_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geometry_column_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgeo_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3064\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vli2016'"
     ]
    }
   ],
   "source": [
    "# Calculating median for vli and vli % of all hh in tract\n",
    "\n",
    "median_vli = data['vli2016'].median()\n",
    "print(\"the median of very low income households at the year 2016 from total households, \"  \n",
    "      \"of all census tracts is: {:.2f}\".format(median_vli))\n",
    "\n",
    "# VLI tract (2016)\n",
    "data['vli_tract16'] = np.where(data['vli2016'] > 0.5, 1, 0)\n",
    "print(\"\\nNumber of VLI tracts at 2016: {}\".format(data['vli_tract16'].value_counts()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Income tract\n",
    "- calculate the median % of all tracts\n",
    "- Binary output (0 == low income tract; 1 = not a low income tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the median of low income and very low income households at the year 2016 from total households, of all census tracts is: 0.37\n",
      "\n",
      "Number of LI tracts at 2016: 2521\n",
      "Number of LI tracts at 2000: 2491\n",
      "Number of LI tracts at 1990: 2513\n"
     ]
    }
   ],
   "source": [
    "# Calculating median for li and vli % of all hh in tract\n",
    "\n",
    "medianli = data['vli2016'].median() + data['li2016'].median()\n",
    "print(\"the median of low income and very low income households at the year 2016 from total households, \"  \n",
    "      \"of all census tracts is: {:.2f}\".format(medianli))\n",
    "\n",
    "# LI 2016\n",
    "data['li_tract16'] = np.where(data['vli2016']+data['li2016'] > medianli, 1, 0)\n",
    "print(\"\\nNumber of LI tracts at 2016: {}\".format(data['li_tract16'].value_counts()[1]))\n",
    "\n",
    "# LI 2000\n",
    "data['li_tract00'] = np.where(data['vli2000']+data['li2000'] > (data['vli2000'].median() + data['li2000'].median()), 1, 0)\n",
    "print(\"Number of LI tracts at 2000: {}\".format(data['li_tract00'].value_counts()[1]))\n",
    "\n",
    "# LI 1990\n",
    "data['li_tract90'] = np.where(data['vli1990']+data['li1990'] > (data['vli1990'].median() + data['li1990'].median()), 1, 0)\n",
    "print(\"Number of LI tracts at 1990: {}\".format(data['li_tract90'].value_counts()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ownership / Rentals oriented\n",
    "Does the tract has more than 50% renters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1990, 1854 tracts were Renters-oriented while 2904 Ownerships-oriented\n",
      "In 2000, 1993 tracts were Renters-oriented while 2765 Ownerships-oriented\n",
      "In 2016, 1966 tracts were Renters-oriented while 2792 Ownerships-oriented\n"
     ]
    }
   ],
   "source": [
    "data['rentOriented_90'] = np.where(data['per_rent90'] >= 0.5, 1, 0)\n",
    "data['rentOriented_00'] = np.where(data['per_rent00'] >= 0.5, 1, 0)\n",
    "data['rentOriented_16'] = np.where(data['per_rent16'] >= 0.5, 1, 0)\n",
    "\n",
    "print('In 1990, {} tracts were Renters-oriented while {} Ownerships-oriented'.format(\n",
    "                                            data['rentOriented_90'].value_counts()[1],\n",
    "                                            data['rentOriented_90'].value_counts()[0]))\n",
    "print('In 2000, {} tracts were Renters-oriented while {} Ownerships-oriented'.format(\n",
    "                                            data['rentOriented_00'].value_counts()[1],\n",
    "                                            data['rentOriented_00'].value_counts()[0]))\n",
    "print('In 2016, {} tracts were Renters-oriented while {} Ownerships-oriented'.format(\n",
    "                                            data['rentOriented_16'].value_counts()[1],\n",
    "                                            data['rentOriented_16'].value_counts()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rent / Home Value < regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['marketLow_90'] = np.where((data['rentOriented_90'] == 1) &\n",
    "                               (data['mrent90']<data['mrent90'].median()),\n",
    "                               1, 0)\n",
    "data['hvalLow_90'] = np.where((data['rentOriented_90'] == 0) &\n",
    "                              (data['mhval90']<data['mhval90'].median()),\n",
    "                              1, 0)\n",
    "data['rentLow_00'] = np.where((data['rentOriented_90'] == 1) &\n",
    "                              (data['mrent90']<data['mrent90'].median()),\n",
    "                              1, 0)\n",
    "data['hvalLow_00'] = np.where((data['rentOriented_90'] == 0) &\n",
    "                              (data['mhval00']<data['mhval00'].median()),\n",
    "                              1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % renters > regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['renters%90'] = np.where(data['per_rent90'] > data['per_rent90'].median(), 1, 0)\n",
    "data['renters%00'] = np.where(data['per_rent00'] > data['per_rent00'].median(), 1, 0)\n",
    "data['renters%16'] = np.where(data['per_rent16'] > data['per_rent16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % college educated < regional median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['edulow90'] = np.where(data['per_col90'] < data['per_col90'].median(), 1, 0)\n",
    "data['edulow00'] = np.where(data['per_col00'] < data['per_col00'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % nonwhite > regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nonwhiteHigh90'] = np.where(data['per_nonwhite90'] > data['per_nonwhite90'].median(), 1, 0)\n",
    "data['nonwhiteHigh00'] = np.where(data['per_nonwhite00'] > data['per_nonwhite00'].median(), 1, 0)\n",
    "data['nonwhiteHigh16'] = np.where(data['per_nonwhite16'] > data['per_nonwhite16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of units in pre-1950 buildings > regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['units_pre50_High'] = np.where(data['per_units_pre50'] > data['per_units_pre50'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment density (2015) > regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['empdens16_High'] = np.where(data['empd15'] > data['empd15'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population stable / growing 1990-2000; 2000-2016\n",
    "first step: recalculating **population growth in 90-00; 00-16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recalculating popgrowth 90-00; 00-16\n",
    "data['popgrowth90-00'] = data['pop00'] - data['pop90']\n",
    "data['popgrowth00-16'] = data['pop16'] - data['pop00']\n",
    "\n",
    "# Stable / Growing\n",
    "data['pgrowth90-00_High'] = np.where(data['popgrowth90-00'] >= 0, 1, 0)\n",
    "data['pgrowth00-16_High'] = np.where(data['popgrowth00-16'] >= 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Density < regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['popDensLow16'] = np.where(data['pop_density16'] < data['pop_density16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss of LI households 1990-2000; 2000-2016 (_absolute loss_)\n",
    "- ch_all_li_count90_00 < 0\n",
    "- ch_all_li_count00_16 < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['lossLI90-00'] = np.where(data['ch_all_li_count90_00'] < 0, 1, 0)\n",
    "data['lossLI00-16'] = np.where(data['ch_all_li_count00_16'] < 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LI migration rate in 2015 < in 2009\n",
    "\n",
    "per_limove09 > per_limove16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['moveinLI_decrease00'] = np.where(data['per_limove16'] < data['per_limove09'], 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Educated growth > region median\n",
    "1. Calculate change in college educators % 90-00, 00-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['edu_change90-00'] = data['per_col00'] - data['per_col90']\n",
    "data['edu_change00-16'] = data['per_col_16'] - data['per_col00']\n",
    "\n",
    "data['edugrowth_High90'] = np.where(data['edu_change90-00'] > data['edu_change90-00'].median(), 1, 0)\n",
    "data['edugrowth_High00'] = np.where(data['edu_change00-16'] > data['edu_change00-16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of households w children for 90,00,16 < regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lessChildren90'] = np.where(data['per_hhwchild_90'] < data['per_hhwchild_90'].median(), 1, 0)\n",
    "data['lessChildren00'] = np.where(data['per_hhwchild_00'] < data['per_hhwchild_00'].median(), 1, 0)\n",
    "data['lessChildren16'] = np.where(data['per_hhwchild_16'] < data['per_hhwchild_16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Growth in real median household income (% change) > regional median (90 and 00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['hhIncomeGrowthHigh90'] = np.where(data['pct_ch_hinc90_00'] > data['pct_ch_hinc90_00'].median(), 1, 0)\n",
    "data['hhIncomeGrowthHigh00'] = np.where(data['pct_ch_hinc00_16'] > data['pct_ch_hinc00_16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rent change 90-00; 00-16 and home value change 90-00; 00-16 > regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1990 base\n",
    "data['rentchange_High90'] = np.where(data['mrent90_00'] > data['mrent90_00'].median(), 1, 0)\n",
    "data['rhomeValchange_High90'] = np.where(data['mhval90_00'] > data['mhval90_00'].median(), 1, 0)\n",
    "\n",
    "# 2000 base\n",
    "data['rentchange_High00'] = np.where(data['mrent00_16'] > data['mrent00_16'].median(), 1, 0)\n",
    "data['rhomeValchange_High00'] = np.where(data['mhval00_16'] > data['mhval00_16'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rail station (TOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4012\n",
       "1.0     746\n",
       "Name: TOD, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TOD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New built housing > regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['newBuilt_90'] = np.where(data['per_units_post80'] > data['per_units_post80'].median(), 1, 0)\n",
    "data['newBuilt_00'] = np.where(data['per_units_post90'] > data['per_units_post90'].median(), 1, 0)\n",
    "data['newBuilt_16'] = np.where(data['per_units_post00'] > data['per_units_post00'].median(), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic change 90-00, 00-16 (2 out of 3 factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic change 90-00\n",
    "def Dchange90(df):\n",
    "    if df['edugrowth_High90'] == 1 and df['hhIncomeGrowthHigh90'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "# Demographic change 00-16\n",
    "def Dchange00(df):\n",
    "    if df['edugrowth_High00'] == 1 and df['hhIncomeGrowthHigh00'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "\n",
    "data['Dchange90'] = data.apply(Dchange90, axis=1)\n",
    "data['Dchange00'] = data.apply(Dchange00, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define \"Hot Market\"\n",
    "- Change in median real rent &gt; regional median<br>\n",
    "**or**<br>\n",
    "- Change in median value for owner-occupied homes &gt; regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1990, 0.55 of the tracts in the data were defined as 'Hot Market'\n",
      "In 2000, 0.51 of the tracts in the data were defined as 'Hot Market'\n"
     ]
    }
   ],
   "source": [
    "def hotmarket90(df):\n",
    "    if df['rentOriented_90'] == 1 and df['rentchange_High90'] == 1:\n",
    "        val = 1\n",
    "    elif df['rentOriented_90'] == 0 and df['rhomeValchange_High90'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "def hotmarket00(df):\n",
    "    if df['rentOriented_00'] == 1 and df['rentchange_High00'] == 1:\n",
    "        val = 1\n",
    "    elif df['rentOriented_00'] == 0 and df['rhomeValchange_High00'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "data['hotmarket90'] = data.apply(hotmarket90, axis=1)\n",
    "data['hotmarket00'] = data.apply(hotmarket00, axis=1)\n",
    "\n",
    "print(\"In 1990, {:.2f} of the tracts in the data were defined as 'Hot Market'\".format(\n",
    "                                            data['hotmarket90'].value_counts([1])[1]))\n",
    "print(\"In 2000, {:.2f} of the tracts in the data were defined as 'Hot Market'\".format(\n",
    "                                            data['hotmarket00'].value_counts([1])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 1.3 Define _Vulnerable to gentrification_ in 1990 or 2000\n",
    "\n",
    "- Housing affordable in base year (_Tract not a “Hot market”_) and (**any 2 of 4**):\n",
    "    - % low income households &gt; regional median\n",
    "    - % college educated &lt; regional median\n",
    "    - % renters &gt; regional median\n",
    "    - % nonwhite &gt; regional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1990, 0.46 of the tracts were defined as 'Vulnerable'\n",
      "In 2000, 0.48 of the tracts were defined as 'Vulnerable'\n"
     ]
    }
   ],
   "source": [
    "def vulnerable90(df):\n",
    "    if df['hvalLow_90']==1 and df['li_tract90']==1 and df['edulow90']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_90']==1 and df['li_tract90']==1 and df['renters%90']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_90']==1 and df['li_tract90']==1 and df['nonwhiteHigh90']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_90']==1 and df['edulow90']==1 and df['renters%90']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_90']==1 and df['edulow90']==1 and df['nonwhiteHigh90']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_90']==1 and df['renters%90']==1 and df['nonwhiteHigh90']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_90']==1 and df['li_tract90']==1 and df['edulow90']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_90']==1 and df['li_tract90']==1 and df['renters%90']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_90']==1 and df['li_tract90']==1 and df['nonwhiteHigh90']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_90']==1 and df['edulow90']==1 and df['renters%90']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_90']==1 and df['edulow90']==1 and df['nonwhiteHigh90']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_90']==1 and df['renters%90']==1 and df['nonwhiteHigh90']==1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "def vulnerable00(df):\n",
    "    if df['hvalLow_00']==1 and df['li_tract00']==1 and df['edulow00']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_00']==1 and df['li_tract00']==1 and df['renters%00']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_00']==1 and df['li_tract00']==1 and df['nonwhiteHigh00']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_00']==1 and df['edulow00']==1 and df['renters%00']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_00']==1 and df['edulow00']==1 and df['nonwhiteHigh00']==1:\n",
    "        val = 1\n",
    "    elif df['hvalLow_00']==1 and df['renters%00']==1 and df['nonwhiteHigh00']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_00']==1 and df['li_tract00']==1 and df['edulow00']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_00']==1 and df['li_tract00']==1 and df['renters%00']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_00']==1 and df['li_tract00']==1 and df['nonwhiteHigh00']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_00']==1 and df['edulow00']==1 and df['renters%00']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_00']==1 and df['edulow00']==1 and df['nonwhiteHigh00']==1:\n",
    "        val = 1\n",
    "    elif df['rentLow_00']==1 and df['renters%00']==1 and df['nonwhiteHigh00']==1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "data['vulnerable90'] = data.apply(vulnerable90, axis=1)\n",
    "data['vulnerable00'] = data.apply(vulnerable00, axis=1)\n",
    "\n",
    "print(\"In 1990, {:.2f} of the tracts were defined as 'Vulnerable'\".format(\n",
    "                                data['vulnerable90'].value_counts([1])[1]))\n",
    "print(\"In 2000, {:.2f} of the tracts were defined as 'Vulnerable'\".format(\n",
    "                                data['vulnerable00'].value_counts([1])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Define risk of gentrification\n",
    "4 out of the 8 of the following is true in 2016:\n",
    "- Located downtown\n",
    "- % of units in pre-1950 buildings > regional median\n",
    "- Share of renter households > regional median\n",
    "- Share of households with children < regional median\n",
    "- Share of recent new-build housing > regional median\n",
    "- Employment density < regional median\n",
    "- Population density < regional median\n",
    "- “Hot market”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk16(df):\n",
    "    if df['downtown'] == 1 and df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['lessChildren16'] == 1:\n",
    "        val = 1\n",
    "    elif df['downtown'] == 1 and df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['newBuilt_16'] == 1:\n",
    "        val = 1\n",
    "    elif df['downtown'] == 1 and df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['empdens16_High'] == 1:\n",
    "        val = 1   \n",
    "    elif df['downtown'] == 1 and df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['popDensLow16'] == 1:\n",
    "        val = 1     \n",
    "    elif df['downtown'] == 1 and df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['hotmarket00'] == 1:\n",
    "        val = 1\n",
    "    elif df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['newBuilt_16'] == 1:\n",
    "        val = 1\n",
    "    elif df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['empdens16_High'] == 1:\n",
    "        val = 1\n",
    "    elif df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['popDensLow16'] == 1:\n",
    "        val = 1\n",
    "    elif df['units_pre50_High'] == 1 and df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['hotmarket00'] == 1:\n",
    "        val = 1    \n",
    "    elif df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['newBuilt_16'] == 1 and df['empdens16_High'] == 1:\n",
    "        val = 1\n",
    "    elif df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['newBuilt_16'] == 1 and df['popDensLow16'] == 1:\n",
    "        val = 1\n",
    "    elif df['renters%16'] == 1 and df['lessChildren16'] == 1 and df['newBuilt_16'] == 1 and df['hotmarket00'] == 1:\n",
    "        val = 1\n",
    "    elif df['lessChildren16'] == 1 and df['newBuilt_16'] == 1 and df['empdens16_High'] == 1 and df['popDensLow16'] == 1:\n",
    "        val=1\n",
    "    elif df['lessChildren16'] == 1 and df['newBuilt_16'] == 1 and df['empdens16_High'] == 1 and df['hotmarket00'] == 1:\n",
    "        val=1\n",
    "    elif df['newBuilt_16'] == 1 and df['empdens16_High'] == 1 and df['popDensLow16'] == 1 and df['hotmarket00'] == 1:\n",
    "        val=1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "data['risk16'] = data.apply(risk16, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Gentrified 90 + Gentrified 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 1990 to 2000, 308 tracts were Gentrified\n",
      "From 2000 to 2016, 369 tracts were Gentrified\n"
     ]
    }
   ],
   "source": [
    "data['Gentrified90'] = np.where((data['vulnerable90'] == 1) &\n",
    "                                (data['Dchange90'] == 1) &\n",
    "                                (data['hotmarket90'] == 1), 1, 0)\n",
    "data['Gentrified00'] = np.where((data['vulnerable00'] == 1) & \n",
    "                                (data['Dchange00'] == 1) &\n",
    "                                (data['hotmarket00'] == 1) &\n",
    "                                (data['moveinLI_decrease00'] == 1), 1, 0)\n",
    "\n",
    "\n",
    "print(\"From 1990 to 2000, {} tracts were Gentrified\".format(\n",
    "                     data['Gentrified90'].value_counts()[1]))\n",
    "print(\"From 2000 to 2016, {} tracts were Gentrified\".format(\n",
    "                     data['Gentrified00'].value_counts()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Classify census tracts by typologies\n",
    "•\tIf any individual variable is missing, then the whole typology is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _LI - Not Losing Low-Income Households_\n",
    "    - Pop in 2000>500\n",
    "    - Low Income Tract in 2015\n",
    "    - Not classified as At Risk of, Ongoing, or Advanced Gentrification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LInotlosing(df):\n",
    "    \n",
    "data['NotloseLI'] = np.where((data['li_tract16'] == 1) & (data['AtRiskGen'] == 0) &\n",
    "                             (data['OngoingGenLI'] == 0) & (data['AdvancedGen'] == 0), 1, 0)\n",
    "\n",
    "data['NotloseLI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('risk00', 'occurred at index 34003003200')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-4d2b56419ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Typology'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTypology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Typology'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-4d2b56419ef8>\u001b[0m in \u001b[0;36mTypology\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# At Risk of Gentrification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'li_tract16'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk00'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vulnerable00'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LI - At Risk of Gentrification'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3118\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3119\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3102\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3104\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3105\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('risk00', 'occurred at index 34003003200')"
     ]
    }
   ],
   "source": [
    "def Typology(df):\n",
    "    '''\n",
    "    classify tracts to a typology, on the range \n",
    "    between LI-not losing LI HH through displacement\n",
    "    and gentrification, to exclusion of LI HH.\n",
    "    Divided to four LI and four MHI typologies\n",
    "    '''\n",
    "    \n",
    "    ## LI typologies\n",
    "    # Ongoing Gentrification \n",
    "    # gentrified in 90, LI tract in 2015\n",
    "    if df['li_tract16'] == 1 and df['Gentrified90'] == 1:\n",
    "        val = 'LI - Ongoing Gentrification'\n",
    "    # gentrified in 00, LI tract in 2015\n",
    "    elif df['li_tract16'] == 1 and df['Gentrified00'] == 1:\n",
    "        val = 'LI - Ongoing Gentrification'\n",
    "        \n",
    "    # Ongoing Displacement of Low- Income Households\n",
    "    elif df['li_tract16'] == 1 and df['lossLI00-16'] == 1 and df['moveinLI_decrease00'] == 1:\n",
    "        val = 'LI - Ongoing Displacement of Low- Income Households'\n",
    "        \n",
    "    # At Risk of Gentrification\n",
    "    elif df['li_tract16'] == 1 and df['risk16'] == 1 and df['vulnerable00'] == 1:\n",
    "        val = 'LI - At Risk of Gentrification'\n",
    "    \n",
    "    # ANot Losing Low-Income Households\n",
    "    elif df['li_tract16'] == 1:\n",
    "        val = 'LI - Not Losing Low-Income Households'\n",
    "    \n",
    "    ## MHI typologies\n",
    "    # Displacement of LI hh - Ongoing Exclusion \n",
    "    elif df['li_tract16'] == 0 and df['pgrowth00-16_High'] == 1 and df['lossLI00-16'] == 1 and df['moveinLI_decrease00'] == 1:\n",
    "        val = 'MHI - Displacement of LI hh - Ongoing Exclusion' \n",
    "    \n",
    "    # At Risk of Exclusion\n",
    "    elif df['li_tract16'] == 0 # add here:\n",
    "        val = 'MHI - At Risk of Exclusion' \n",
    "    \n",
    "    # Not Losing Low-Income Households\n",
    "    elif df['li_tract16'] == 0 # add here:\n",
    "        val = 'MHI - Not Losing Low-Income Households'\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        val = \"TBD\"\n",
    "    return val\n",
    "\n",
    "data['Typology'] = data.apply(Typology, axis=1)\n",
    "data['Typology'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _MHI - Advanced / Completed Gentrification_\n",
    "    - Pop in 2000>500\n",
    "    - Moderate to High Income Tract in 2015\n",
    "    - Gentrified in in 1990-2000 or 2000-2015 (Defined in Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Gentrification (Moderate to High Income)\n",
    "\n",
    "def AdvancedGen(df):\n",
    "    if df['li_tract16'] == 0 and df['Gentrified90'] == 1 and df['VLI'] == 0:\n",
    "        val = 1\n",
    "    elif df['li_tract16'] == 0 and df['Gentrified00'] == 1 and df['VLI'] == 0:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AdvancedGen'] = data.apply(AdvancedGen, axis=1)\n",
    "data['AdvancedGen'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _4. LI - Ongoing Gentrification_\n",
    "\n",
    "    - Pop in 2000 > 500\n",
    "    - Low Income Tract in 2016\n",
    "    - Vulnerable in 2000 (Defined in Appendix)\n",
    "    - Population stable or growing 2000-2016\n",
    "    - Loss of LI households 2000-2016 (absolute loss)\n",
    "    - Either:\n",
    "        o “Hot market” (Defined in Appendix)\n",
    "        o LI migration rate (percent of all migration to tract that was LI)\n",
    "    in 2016 < in 2009\n",
    "    - Gentrified in 1990-2000 or 2000-2016 (Defined in Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Typology' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7afb65cb9d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Typology'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTypology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Typology'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Typology' is not defined"
     ]
    }
   ],
   "source": [
    "# Displacement of LowIncome Households/Ongoing Gentrification (Low Income)\n",
    "\n",
    "def OngoingGenLI(df):\n",
    "    # gentrified in 90, LI tract in 2015\n",
    "    if df['li_tract16'] == 1 and df['Gentrified90'] == 1 and df['AdvancedGen'] == 0:\n",
    "        val = 1\n",
    "    # gentrified in 00, LI tract in 2015\n",
    "    elif df['li_tract16'] == 1 and df['Gentrified00'] == 1 and df['AdvancedGen'] == 0:\n",
    "        val = 1\n",
    "    # LI tract in 2016; Vulnerable in 2000; pop growth; Loss of LI households; hot market in 90\n",
    "    elif df['li_tract16'] == 1 and df['Volnurable00'] == 1 and df['popgrowth00-16'] == 1\\\n",
    "        and df['lossLI00-16'] == 1  and df['hotmarket90'] == 1 and df['AdvancedGen'] == 0:\n",
    "        val = 1\n",
    "    # LI tract in 2016; Vulnerable in 2000; pop growth; Loss of LI households; hot market in 00\n",
    "    elif df['li_tract16'] == 1 and df['Volnurable00'] == 1 and df['popgrowth00-16'] == 1\\\n",
    "        and df['lossLI00-16'] == 1 and df['hotmarket00'] == 1 and df['AdvancedGen'] == 0:\n",
    "        val = 1\n",
    "    #     # LI tract in 2016; Vulnerable in 2000; pop growth; Loss of LI households; LI migration rate\n",
    "    elif df['li_tract16'] == 1 and df['Volnurable00'] == 1 and df['popgrowth00-16'] == 1\\\n",
    "        and df['lossLI00-16'] == 1 and df['moveinLI_decrease00'] == 1 and df['AdvancedGen'] == 0:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OngoingGenLI'] = data.apply(OngoingGenLI, axis=1)\n",
    "data['OngoingGenLI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# _LI - At Risk of Gentrification _\n",
    "- Volnurable in 2000 (3 out of 4 variables)\n",
    "- Not currently undergoing displacement or ongoing gentrification\n",
    "- 2 out of the 4 of the following is true in 2015( select only one 'hot market' from the 2 'hot market' option)\n",
    "- Not currently undergoing displacement or ongoing gentrification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AtRiskGen'] = np.where((data['li_tract16'] == 1) & (data['Volnurable00'] == 1) &\n",
    "                            (data['risk00'] == 1) & (data['OngoingGenLI'] == 0), 1, 0)\n",
    "\n",
    "data['AtRiskGen'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. _LI - Stable (Not losing LI hh)_\n",
    "   -  _'pop00'_ (>500)\n",
    "   - Low Income tract in 2015\n",
    "   - Not classified as At Risk of, Ongoing, or Advanced Gentrification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NotloseLI'] = np.where((data['li_tract16'] == 1) & (data['AtRiskGen'] == 0) &\n",
    "                             (data['OngoingGenLI'] == 0) & (data['AdvancedGen'] == 0), 1, 0)\n",
    "\n",
    "data['NotloseLI'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _8. MHI - Exclusion_\n",
    "    - Pop in 2000 > 500\n",
    "    - Moderate to High Income Tract in 2015\n",
    "    - <20% LI in 2000 \n",
    "    - % LI in 2016 < % LI in 2000\n",
    "    - LI migration < regional median in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LI<20%'] = np.where(data['li2016']+data['vli2016'] < 0.2, 1, 0)\n",
    "data['%LIdecrease'] = np.where(data['li2016'] < data['li2000'], 1, 0)\n",
    "data['migLI_low'] = np.where(data['per_limove16'] < data['per_limove16'].median(), 1, 0)\n",
    "\n",
    "data.iloc[:,-3:].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Exclusion\n",
    "\n",
    "def Exclusion(df):\n",
    "    if df['li_tract16'] == 0 and df['LI<20%'] == 1 and df['%LIdecrease'] == 1 and df['migLI_low'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Exclusion'] = data.apply(Exclusion, axis=1)\n",
    "data['Exclusion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _7. MHI - At Risk of Exclusion_\n",
    "\n",
    "    - Pop in 2000 > 500\n",
    "    - Moderate to High Income Tract in 2015\n",
    "    - 2 out of the 4 of the following is true in 2015:\n",
    "        o Has rail station in tract\n",
    "        o % of units in prewar buildings (1950) > regional median\n",
    "        o Employment density> regional median\n",
    "        o “Hot market” (options defined below table)\n",
    "    - Not currently undergoing exclusion – none of the below classifications are met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AtRiskExc'] = np.where((data['li_tract16'] == 0) & (data['risk00'] == 1) &\n",
    "                            (data['Exclusion'] == 0), 1, 0)\n",
    "\n",
    "data['AtRiskExc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _6. MHI - Stable (Not Losing Low-Income Households)_\n",
    "    - Pop in 2000>500\n",
    "    - Moderate to High Income Tract in 2015\n",
    "    - Not classified as At Risk of, Ongoing, or Advanced Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NotloseHigh'] = np.where((data['li_tract16'] == 0) & (data['AtRiskExc'] == 0) &\n",
    "                            (data['Exclusion'] == 0), 1, 0)\n",
    "\n",
    "data['NotloseHigh'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  << TYPOLOGY >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Typology(df):\n",
    "    if df['VLI'] == 1:\n",
    "        val = 'VLI - Highly Vulnerable for Displacement'\n",
    "    elif df['AdvancedGen'] == 1:\n",
    "        val = 'MHI - Advanced Gentrification'\n",
    "    elif df['Exclusion'] == 1:\n",
    "        val = 'MHI - Exclusion' \n",
    "    elif df['AtRiskExc'] == 1:\n",
    "        val = 'MHI - At Risk of Exclusion'\n",
    "    elif df['NotloseHigh'] == 1:\n",
    "        val = 'MHI - Stable, Not Losing Low Income Households'\n",
    "    elif df['OngoingGenLI'] == 1:\n",
    "        val = 'LI - Ongoing Gentrification and/or Displacement'\n",
    "    elif df['AtRiskGen'] == 1:\n",
    "        val = 'LI - At Risk of Gentrification and/or Displacement'\n",
    "    elif df['NotloseLI'] == 1:\n",
    "        val = 'LI - Stable, Not Losing Low Income Households'\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Typology'] = data.apply(Typology, axis=1)\n",
    "data['Typology'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.DataFrame(data['Typology']))#.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsTyp = pd.DataFrame(data['Typology'].value_counts())\n",
    "resultsTyp.columns = ['tractCounts']\n",
    "resultsTyp['Typology%'] = resultsTyp['tractCounts'] / resultsTyp['tractCounts'].sum() *100\n",
    "\n",
    "resultsTyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsTyp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[['GEOid2', 'Typology']].set_index('GEOid2').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['GEOid2', 'Typology']].set_index('GEOid2').to_csv('UDPNY_revisedTypologies2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.pie(resultsTyp.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
